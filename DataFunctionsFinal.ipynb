{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell for troubleshooting/Inputting the Week_Nums\n",
    "week_nums = [200530,200606,200613, 200620]\n",
    "\n",
    "#2019 [190601,190608,190615, 190622]\n",
    "#2020 [200530,200606,200613, 200620]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(week_nums):\n",
    "    '''\n",
    "    Takes in a list of weeks, returns a dataframe with the CSV's combined and time \n",
    "    \n",
    "    ~~~~\n",
    "    Parameters\n",
    "    ----\n",
    "    week_nums : TYPE = list (int)\n",
    "\n",
    "    Returns\n",
    "    ----\n",
    "    dfs : TYPE = dataframe\n",
    "    \n",
    "    '''\t\n",
    "    dfs = []\n",
    "    for week_num in week_nums: #Fetch data from MTA site for matching weeks\n",
    "        url = \"http://web.mta.info/developers/data/nyct/turnstile/turnstile_{}.txt\"\n",
    "        file_url = url.format(week_num)\n",
    "        names = ['c_a', 'unit', 'scp', 'station', 'linename', 'division', \n",
    "                 'date', 'time', 'desc', 'entries', 'exits']\n",
    "        df = pd.read_csv(file_url, names=names, parse_dates=[['date','time']], \n",
    "                         keep_date_col=True, skiprows=1)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df['day_of_week'] = df['date_time'].dt.day_name()\n",
    "        df = df[(~df['c_a'].str.contains('PTH') & \n",
    "                 ~df['desc'].str.contains('RECOVR') & \n",
    "                 df.time.astype(str).str.contains('00:00'))]\n",
    "        df = df[['station', 'unit', 'c_a', 'scp', 'date_time', 'date', 'day_of_week', 'time', \n",
    "                'desc', 'entries', 'exits']]\n",
    "        #delete duplicates -> could be done after dataframe creation instead of in this loop\n",
    "        df.sort_values(['c_a', 'unit', 'scp', 'station', 'date_time'], inplace=True, ascending=False)\n",
    "        df.drop_duplicates(subset=['c_a', 'unit', 'scp', 'station', 'date_time'], inplace=True)\n",
    "        dfs.append(df)\n",
    "        #For troubleshooting: print(week_num)\n",
    "    return pd.concat(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_entry(row, max_counter):\n",
    "    '''\n",
    "    When called, takes in a row number and a max counter value and applies a test to see if the counter makes sense, then returns the delta between entries.\n",
    "    \n",
    "    ~~~~\n",
    "    Parameters\n",
    "    ----\n",
    "    row : TYPE = int (row number in a dataframe)\n",
    "    max_counter : TYPE = int\n",
    "\n",
    "    Returns\n",
    "    ----\n",
    "    counter : TYPE = int\n",
    "    \n",
    "    '''\n",
    "    counter = row[\"entries\"] - row[\"prev_entries\"]\n",
    "    if counter < 0:\n",
    "        # Maybe counter is reversed?\n",
    "        counter = -counter\n",
    "    if counter > max_counter:\n",
    "        # Maybe counter was reset to 0? \n",
    "        #print(row[\"entries\"], row[\"prev_entries\"])\n",
    "        counter = min(row[\"entries\"], row[\"prev_entries\"])\n",
    "    if counter > max_counter:\n",
    "        # Check it again to make sure we're not still giving a counter that's too big\n",
    "        return 0\n",
    "    if row[\"date_time\"] - row[\"prev_datetime\"] > timecop:\n",
    "        return 0\n",
    "    return counter\n",
    "\n",
    "def get_counts_exit(row, max_counter):\n",
    "    '''\n",
    "    When called, takes in a row number and a max counter value and applies a test to see if the counter makes sense, then returns the delta between exits.\n",
    "    \n",
    "    ~~~~\n",
    "    Parameters\n",
    "    ----\n",
    "    row : TYPE = int (row number in a dataframe)\n",
    "    max_counter : TYPE = int\n",
    "\n",
    "    Returns\n",
    "    ----\n",
    "    counter : TYPE = int\n",
    "    \n",
    "    '''\n",
    "    counter = row[\"exits\"] - row[\"prev_exits\"]\n",
    "    if counter < 0:\n",
    "        # Maybe counter is reversed?\n",
    "        counter = -counter\n",
    "    if counter > max_counter:\n",
    "        # Maybe counter was reset to 0? \n",
    "        #print(row[\"exits\"], row[\"prev_exits\"])\n",
    "        counter = min(row[\"exits\"], row[\"prev_exits\"])\n",
    "    if counter > max_counter:\n",
    "        # Check it again to make sure we're not still giving a counter that's too big\n",
    "        return 0\n",
    "    if row[\"date_time\"] - row[\"prev_datetime\"] > timecop:\n",
    "        return 0\n",
    "    return counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turnstile(week_nums):\n",
    "    '''\n",
    "    Main function.\n",
    "    Takes in a list of weeks, returns a dataframe with to be plotted with calculations done. Calls other functions.\n",
    "    \n",
    "    ~~~~\n",
    "    Parameters\n",
    "    ----\n",
    "    week_nums : TYPE = list (int)\n",
    "\n",
    "    Returns\n",
    "    ----\n",
    "    unit_hourly : TYPE = dataframe\n",
    "    \n",
    "    '''\t\n",
    "    #get data from web\n",
    "    turnstiles_df = clean(week_nums)\n",
    "    \n",
    "    #add column specifying the prior block of time to find the change in total entries / exits\n",
    "    '''\n",
    "    This code creates groups based on SCP (physical turnstile lanes).\n",
    "    '''\n",
    "   \n",
    "    turnstiles_block = (turnstiles_df\n",
    "                        .groupby([\"c_a\", \"unit\", \"scp\", \"station\", \"date_time\", \"exits\"],as_index=False).entries.first())\n",
    "    turnstiles_block[[\"prev_datetime\", \"prev_entries\", \"prev_exits\"]] = (turnstiles_block\n",
    "                                                                         .groupby([\"c_a\", \"unit\", \"scp\", \"station\"])[\"date_time\", \"entries\", \"exits\"]\n",
    "                                                                         .apply(lambda grp: grp.shift(1)))\n",
    "\n",
    "    turnstiles_block.dropna(subset=[\"prev_datetime\"], axis=0, inplace=True)\n",
    "    #filter outlier exit and entry counts\n",
    "    '''\n",
    "    It is thought that it takes a minimum of 5 seconds to go through a turnstile. This means 2880 theoretical max input from an SCP in a 4 hour period. Increasing this by a factor of 5 gives us 14400, or about 15000\n",
    "    '''\n",
    "    timecop = (pd.to_datetime(140, unit='h')-pd.to_datetime(131, unit='h')) #timecop, enforcing temporal violations.\n",
    "    \n",
    "    #turnstiles_block['delta_entries'] = turnstiles_block.apply(get_counts_entry, axis=1, max_counter=15000)\n",
    "    #Above line removed for performance reasons.\n",
    "    #15000 max_counter value based on an order of magnitude larger than the highest possible values for SCP.\n",
    "    turnstiles_block['delta_exits'] = turnstiles_block.apply(get_counts_exit, axis=1, max_counter=15000)\n",
    "\n",
    "    #group turnstiles by time block, total\n",
    "    '''\n",
    "    This code sums turnstiles into Units (Remote units), or physical station locations based on billing. It keeps different names of stations still separate.\n",
    "    '''\n",
    "    unit_hourly = (turnstiles_block.groupby(['station','unit','date_time'])['delta_exits'].sum().reset_index())\n",
    "    #unit_hourly = (turnstiles_block.groupby(['station','unit','date_time'])['delta_exits','delta_entries'].sum().reset_index())\n",
    "    \n",
    "    return unit_hourly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call other functions = Use this to create the dataframe to plot\n",
    "unit_hourly = turnstile(week_nums)\n",
    "#For troubleshooting:Create copy of turnstile so that we have backup dataframe\n",
    "#unit_copy = unit_hourly.copy()\n",
    "\n",
    "#Dataframe that sums exit/entry counts count by station / time blocks overall (even with stations that have 2 different names)\n",
    "top = unit_hourly.groupby(['unit', 'date_time'])['delta_exits'].sum().reset_index()\n",
    "#unit_hourly.groupby(['unit', 'date_time'])['delta_exits','delta_entries'].sum().reset_index()\n",
    "\n",
    "#head length variable-> visually assess list til 10 uniques\n",
    "top10 = (top.sort_values(by=['delta_exits'],ascending=False)\n",
    "        .unit)\n",
    "\n",
    "#Selecting top 10/5 units.\n",
    "top10units = top10.unique()[:10]\n",
    "top5units = top10.unique()[:5]\n",
    "\n",
    "#creating a dictionary of unit and names of stations\n",
    "unit_list = (unit_hourly.sort_values(by=['date_time'],ascending=False).unit).unique()\n",
    "name_list = {}\n",
    "for unit in unit_list:\n",
    "    mask = (unit_hourly['unit'] == unit)\n",
    "    name_prog = unit_hourly[mask]\n",
    "    s = name_prog['station'].value_counts().idxmax()\n",
    "    name = {unit : s}\n",
    "    name_list.update(name)\n",
    "    \n",
    "    \n",
    "plt.figure(figsize=[15,10])\n",
    "for i in top5units: \n",
    "    mask = (top['unit'] == i)\n",
    "    top5_df = top[mask]\n",
    "    plt.plot(top5_df.date_time, top5_df.delta_exits, label = name_list[top5_df.unit.iloc[0]]) #Only change name of Unit to the corresponding station when graphing, and nowhere else to prevent name conflicts and unit doubling.\n",
    "plt.legend()\n",
    "\n",
    "plt.title('Traffic in the top 5 stations {}'.format(week_nums), fontsize=20, weight='bold',color='b')\n",
    "plt.xlabel('Date', fontsize=15, weight='bold',color='b')\n",
    "plt.ylabel('Traffic', fontsize=15, weight='bold',color='b')\n",
    "plt.savefig('top5 stations traffic.svg')\n",
    "\n",
    "#Depreciated Code\n",
    "#.replace(name_list , inplace=True) #Warning! edits the original dataframe\n",
    "#top.replace(name_list , inplace=True)\n",
    "\n",
    "#fix up the lists made with units earlier\n",
    "#top10units = [name_list.get(item, item) for item in top10units]\n",
    "#top5units = [name_list.get(item, item) for item in top5units]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 ST\n",
      "14 ST-UNION SQ\n",
      "JKSN HT-ROOSVLT\n",
      "BROOKLYN BRIDGE\n",
      "FLUSHING-MAIN\n",
      "42 ST-PORT AUTH\n",
      "JUNCTION BLVD\n",
      "59 ST COLUMBUS\n",
      "SUTPHIN-ARCHER\n",
      "JAMAICA CENTER\n"
     ]
    }
   ],
   "source": [
    "#translate names of units to stations for debugging\n",
    "for i in range(10):\n",
    "    print(name_list[top10units[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
